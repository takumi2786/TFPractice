{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tensorflowエキスパートクイックスタート\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from IPython.core.debugger import Pdb\n",
    "\n",
    "# Pdb().set_trace()\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "# データセットをシャッフルし、バッチ化するために tf.data を使います。\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "# Pdb().set_trace()\n",
    "\n",
    "\n",
    "# Kerasの model subclassing API を使ってtf.kerasモデルを作ります。\n",
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "    self.flatten = Flatten()\n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10, activation='softmax')\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "# モデルのインスタンスを作成\n",
    "model = MyModel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 自作関数による学習の実行\n",
    "# ロス関数，オプティマイザを設定\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "# 学習結果を記録するためのメトリクスを取得\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "\n",
    "# tf.GradientTapeを使ってモデルを訓練します。\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(images)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  predictions = model(images)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)\n",
    "\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  for images, labels in train_ds:\n",
    "    #     Pdb().set_trace()\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()*100))\n",
    "  \n",
    "  # 次のエポック用にメトリクスをリセット\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### メトリクスをテスト\n",
    "m = tf.keras.metrics.Accuracy()\n",
    "\n",
    "m.update_state([[1], [2], [3], [4]], [[0], [2], [3], [1]])\n",
    "# m([[1], [2], [3], [4]], [[0], [2], [3], [4]]) # これも同じ動き\n",
    "m.result().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ZipDataset shapes: ((192, 192, 3), ()), types: (tf.float32, tf.int64)>\n",
      "<ShuffleDataset shapes: ((192, 192, 3), ()), types: (tf.float32, tf.int64)>\n",
      "<RepeatDataset shapes: ((192, 192, 3), ()), types: (tf.float32, tf.int64)>\n",
      "<PrefetchDataset shapes: ((192, 192, 3), ()), types: (tf.float32, tf.int64)>\n",
      "<BatchDataset shapes: ((None, 192, 192, 3), (None,)), types: (tf.float32, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "### tf.dataの練習\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "data_root_orig = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "                                         fname='flower_photos', untar=True)\n",
    "data_root = pathlib.Path(data_root_orig)\n",
    "\n",
    "# \n",
    "attributions = (data_root/\"LICENSE.txt\").open(encoding='utf-8').readlines()[4:]\n",
    "attributions = [line.split(' CC-BY') for line in attributions]\n",
    "attributions = dict(attributions)\n",
    "\n",
    "# 画像のパスリストの取得\n",
    "all_image_paths = list(data_root.glob('*/*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "# 画像の総数\n",
    "image_count = len(all_image_paths)\n",
    "\n",
    "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "# ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "\n",
    "label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
    "# {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\n",
    "\n",
    "all_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in all_image_paths]\n",
    "# First 10 labels indices:  [2, 3, 4, 2, 1, 3, 2, 0, 3, 2]\n",
    "\n",
    "########################################################################################################\n",
    "img_path = all_image_paths[0]\n",
    "img_raw = tf.io.read_file(img_path)# 生のバイナリデータ\n",
    "img_tensor = tf.image.decode_image(img_raw) # numpy配列に変換\n",
    "# Pdb().set_trace()\n",
    "########################################################################################################\n",
    "\n",
    "\n",
    "def caption_image(image_path):\n",
    "  image_rel = pathlib.Path(image_path).relative_to(data_root)\n",
    "  return \"Image (CC BY 2.0) \" + ' - '.join(attributions[str(image_rel)].split(' - ')[:-1])\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=3) # numpy配列に変換\n",
    "  image = tf.image.resize(image, [192, 192])      # リサイズ\n",
    "  image /= 255.0                                  # 正規化\n",
    "  return image\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)                 # 生のバイナリデータ\n",
    "#   Pdb().set_trace()\n",
    "  return preprocess_image(image)\n",
    "\n",
    "\n",
    "# # パス文字列によるデータセット\n",
    "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "\n",
    "# # 画像データセット\n",
    "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# # ラベルデータセット\n",
    "label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n",
    "\n",
    "# #(image, label) というペアのデータセット\n",
    "image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "print(image_label_ds)\n",
    "\n",
    "ds = image_label_ds.shuffle(buffer_size=image_count)\n",
    "print(ds)\n",
    "ds = ds.repeat()\n",
    "print(ds)\n",
    "ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "print(ds)\n",
    "BATCH_SIZE = 32\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "print(ds)\n",
    "\n",
    "# for n,image in enumerate(image_ds.take(4)):\n",
    "#     print(image.shape)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(8,8))\n",
    "# for n,image in enumerate(image_ds.take(4)):\n",
    "#   plt.subplot(2,2,n+1)\n",
    "#   plt.imshow(image)\n",
    "#   plt.grid(False)\n",
    "#   plt.xticks([])\n",
    "#   plt.yticks([])\n",
    "#   plt.xlabel(caption_image(all_image_paths[n]))\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: (192, 192, 3), types: tf.float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ds.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# tf.data.Datasetのハンズオン（非公式） https://qiita.com/Suguru_Toyohara/items/820b0dad955ecd91c7f3\n",
    "# 非公式仮説　https://qiita.com/studio_haneya/items/1138e427367e93cd2ab8\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
    "\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf recordの利用\n",
    "[x_train, y_train], [x_test, y_test] = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "def make_example(image, label):\n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "        'x' : tf.train.Feature(float_list=tf.train.FloatList(value=image)),\n",
    "        'y' : tf.train.Feature(int64_list=tf.train.Int64List(value=label))\n",
    "    }))\n",
    "\n",
    "def write_tfrecord(images, labels, filename):\n",
    "    writer = tf.io.TFRecordWriter(filename)\n",
    "    for image, label in zip(images, labels):\n",
    "        ex = make_example(image.ravel().tolist(), [int(label)])\n",
    "        writer.write(ex.SerializeToString())\n",
    "    writer.close()\n",
    "\n",
    "write_tfrecord(x_train, y_train, '../mnist_train.tfrecord')\n",
    "write_tfrecord(x_test, y_test, '../mnist_test.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.arange(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import contextlib\n",
    "\n",
    "# Some helper code to demonstrate the kinds of errors you might encounter.\n",
    "@contextlib.contextmanager\n",
    "def assert_raises(error_class):\n",
    "  try:\n",
    "    yield\n",
    "  except error_class as e:\n",
    "    print('Caught expected exception \\n  {}:'.format(error_class))\n",
    "    traceback.print_exc(limit=2)\n",
    "  except Exception as e:\n",
    "    raise e\n",
    "  else:\n",
    "    raise Exception('Expected {} to be raised but no error was raised!'.format(\n",
    "        error_class))\n",
    "\n",
    "'''\n",
    "@tf.function\n",
    "def f(x):\n",
    "  v = tf.Variable(1.0)\n",
    "  v.assign_add(x)\n",
    "  return v\n",
    "\n",
    "\n",
    "with assert_raises(ValueError):\n",
    "    f(1.0)\n",
    "'''\n",
    "# 複数回同じVariableを作成する処理を行ってはいけない．∴はじめに関数が呼び出されたときにのみvariableを作成することができる．\n",
    "# 以下のように，元の一回のみ変数定義を行うように書くことで，エラーを回避できる．\n",
    "class Count(tf.Module):\n",
    "  def __init__(self):\n",
    "    self.count = None\n",
    "  \n",
    "  @tf.function\n",
    "  def __call__(self):\n",
    "    if self.count is None:\n",
    "      self.count = tf.Variable(0)\n",
    "    return self.count.assign_add(1)\n",
    "\n",
    "c = Count()\n",
    "print(c())\n",
    "print(c())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
