{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.9 64-bit ('tf_practice': conda)",
   "display_name": "Python 3.6.9 64-bit ('tf_practice': conda)",
   "metadata": {
    "interpreter": {
     "hash": "06405596078a37fd62b2c702c07893b373510b3c77d0358827361cd31606c4c4"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorBoardを使ってみる \n",
    "# ハンズオン: https://www.tensorflow.org/tensorboard/get_started\n",
    "# APIドキュメント: https://www.tensorflow.org/api_docs/python/tf/summary\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.3185 - accuracy: 0.0312WARNING:tensorflow:From /opt/anaconda3/envs/tf_practice/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1875 [..............................] - ETA: 1:09 - loss: 2.2930 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0112s vs `on_train_batch_end` time: 0.0625s). Check your callbacks.\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2188 - accuracy: 0.9348 - val_loss: 0.0986 - val_accuracy: 0.9694\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0974 - accuracy: 0.9701 - val_loss: 0.0733 - val_accuracy: 0.9758\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0690 - accuracy: 0.9784 - val_loss: 0.0740 - val_accuracy: 0.9760\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0531 - accuracy: 0.9825 - val_loss: 0.0613 - val_accuracy: 0.9813\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0428 - accuracy: 0.9860 - val_loss: 0.0629 - val_accuracy: 0.9803\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffbbe9f6fd0>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# モデル構造の可視化\n",
    "!rm -rf ./logs/\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)# CallBackでTensorBoardのためのログを残す．\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\nTensorBoard 2.3.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs/fit\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.3.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape:  (28, 28)\n",
      "Label:  9 -> Ankle boot\n",
      "End\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tf_practice/bin/tensorboard\", line 5, in <module>\n",
      "    from tensorboard.main import run_main\n",
      "  File \"/opt/anaconda3/envs/tf_practice/lib/python3.6/site-packages/tensorboard/main.py\", line 43, in <module>\n",
      "    from tensorboard import default\n",
      "  File \"/opt/anaconda3/envs/tf_practice/lib/python3.6/site-packages/tensorboard/default.py\", line 39, in <module>\n",
      "    from tensorboard.plugins.audio import audio_plugin\n",
      "  File \"/opt/anaconda3/envs/tf_practice/lib/python3.6/site-packages/tensorboard/plugins/audio/audio_plugin.py\", line 26, in <module>\n",
      "    from tensorboard import plugin_util\n",
      "  File \"/opt/anaconda3/envs/tf_practice/lib/python3.6/site-packages/tensorboard/plugin_util.py\", line 27, in <module>\n",
      "    import markdown\n",
      "  File \"/opt/anaconda3/envs/tf_practice/lib/python3.6/site-packages/markdown/__init__.py\", line 29, in <module>\n",
      "    from .core import Markdown, markdown, markdownFromFile  # noqa: E402\n",
      "  File \"/opt/anaconda3/envs/tf_practice/lib/python3.6/site-packages/markdown/core.py\", line 26, in <module>\n",
      "    from . import util\n",
      "  File \"/opt/anaconda3/envs/tf_practice/lib/python3.6/site-packages/markdown/util.py\", line 85, in <module>\n",
      "    INSTALLED_EXTENSIONS = metadata.entry_points().get('markdown.extensions', ())\n",
      "  File \"/opt/anaconda3/envs/tf_practice/lib/python3.6/site-packages/importlib_metadata/__init__.py\", line 596, in entry_points\n",
      "    ordered = sorted(eps, key=by_group)\n",
      "  File \"/opt/anaconda3/envs/tf_practice/lib/python3.6/site-packages/importlib_metadata/__init__.py\", line 594, in <genexpr>\n",
      "    dist.entry_points for dist in distributions())\n",
      "  File \"/opt/anaconda3/envs/tf_practice/lib/python3.6/site-packages/importlib_metadata/__init__.py\", line 289, in entry_points\n",
      "    return EntryPoint._from_text(self.read_text('entry_points.txt'))\n",
      "  File \"/opt/anaconda3/envs/tf_practice/lib/python3.6/site-packages/importlib_metadata/__init__.py\", line 545, in read_text\n",
      "    return self._path.joinpath(filename).read_text(encoding='utf-8')\n",
      "  File \"/opt/anaconda3/envs/tf_practice/lib/python3.6/pathlib.py\", line 1197, in read_text\n",
      "    return f.read()\n",
      "  File \"/opt/anaconda3/envs/tf_practice/lib/python3.6/codecs.py\", line 318, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# グラフ以外のログも残せる？\n",
    "\n",
    "# 画像の表示\n",
    "from datetime import datetime\n",
    "import io\n",
    "import itertools\n",
    "from six.moves import range\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "# Names of the integer classes, i.e., 0 -> T-short/top, 1 -> Trouser, etc.\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "\n",
    "print(\"Shape: \", train_images[0].shape)\n",
    "print(\"Label: \", train_labels[0], \"->\", class_names[train_labels[0]])\n",
    "\n",
    "# Reshape the image for the Summary API.\n",
    "img = np.reshape(train_images[0], (-1, 28, 28, 1))\n",
    "\n",
    "# Clear out any prior log data.\n",
    "!rm -rf logs\n",
    "\n",
    "# Sets up a timestamped log directory.\n",
    "logdir = \"logs/train_data/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Using the file writer, log the reshaped image.\n",
    "with file_writer.as_default():\n",
    "  tf.summary.image(\"Training data\", img, step=0)\n",
    "  tf.summary.scalar(\"test\",tf.constant(3),step=0)\n",
    "  tf.summary.scalar(\"test\",tf.constant(5),step=1)\n",
    "\n",
    "print('End')\n",
    "\n",
    "# TensorBoard起動\n",
    "!tensorboard --logdir logs/train_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 0]\n",
      "[1, 1]\n",
      "[2, 2]\n",
      "[3, 3]\n",
      "[4, 4]\n",
      "[5, 5]\n",
      "[6, 6]\n",
      "[7, 7]\n",
      "[8, 8]\n",
      "[9, 9]\n",
      "[10, 10]\n",
      "[11, 11]\n",
      "[12, 12]\n",
      "[13, 13]\n",
      "[14, 14]\n",
      "[15, 15]\n",
      "[16, 16]\n",
      "[17, 17]\n",
      "[18, 18]\n",
      "[19, 19]\n",
      "[20, 20]\n",
      "[21, 21]\n",
      "[22, 22]\n",
      "[23, 23]\n",
      "[24, 24]\n",
      "[25, 25]\n",
      "[26, 26]\n",
      "[27, 27]\n",
      "[28, 28]\n",
      "[29, 29]\n",
      "[30, 30]\n",
      "[31, 31]\n",
      "[32, 32]\n",
      "[33, 33]\n",
      "[34, 34]\n",
      "[35, 35]\n",
      "[36, 36]\n",
      "[37, 37]\n",
      "[38, 38]\n",
      "[39, 39]\n",
      "[40, 40]\n",
      "[41, 41]\n",
      "[42, 42]\n",
      "[43, 43]\n",
      "[44, 44]\n",
      "[45, 45]\n",
      "[46, 46]\n",
      "[47, 47]\n",
      "[48, 48]\n",
      "[49, 49]\n",
      "[50, 50]\n",
      "[51, 51]\n",
      "[52, 52]\n",
      "[53, 53]\n",
      "[54, 54]\n",
      "[55, 55]\n",
      "[56, 56]\n",
      "[57, 57]\n",
      "[58, 58]\n",
      "[59, 59]\n",
      "[60, 60]\n",
      "[61, 61]\n",
      "[62, 62]\n",
      "[63, 63]\n",
      "[64, 64]\n",
      "[65, 65]\n",
      "[66, 66]\n",
      "[67, 67]\n",
      "[68, 68]\n",
      "[69, 69]\n",
      "[70, 70]\n",
      "[71, 71]\n",
      "[72, 72]\n",
      "[73, 73]\n",
      "[74, 74]\n",
      "[75, 75]\n",
      "[76, 76]\n",
      "[77, 77]\n",
      "[78, 78]\n",
      "[79, 79]\n",
      "[80, 80]\n",
      "[81, 81]\n",
      "[82, 82]\n",
      "[83, 83]\n",
      "[84, 84]\n",
      "[85, 85]\n",
      "[86, 86]\n",
      "[87, 87]\n",
      "[88, 88]\n",
      "[89, 89]\n",
      "[90, 90]\n",
      "[91, 91]\n",
      "[92, 92]\n",
      "[93, 93]\n",
      "[94, 94]\n",
      "[95, 95]\n",
      "[96, 96]\n",
      "[97, 97]\n",
      "[98, 98]\n",
      "[99, 99]\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "# つまり，どうゆうことだってばよ？\n",
    "# tf.summary.create_file_writerとtf.summary.scalarなどを使うことで，様々なデータの時間変化を記録できる．\n",
    "!rm -rf logs\n",
    "import random\n",
    "logdir = \"logs/train_data/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "with writer.as_default():\n",
    "  for step in range(100):\n",
    "    # other model code would go here\n",
    "    # r = [random.random(),random.random()]\n",
    "    # r = [step/100,random.uniform(0, 10)]\n",
    "    r = [step,step]\n",
    "    tf.summary.histogram(\"my_metric\", r, step=step)\n",
    "    writer.flush()\n",
    "    print(r)\n",
    "\n",
    "print('End')\n",
    "\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.3.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs/train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}